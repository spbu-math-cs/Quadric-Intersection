{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demostration and Comparison of Similarity Robustification Methods\n",
    "\n",
    "This jupyter notebook allows to compare different similarity robustification methods in terms of the identification rate (IR) and verification rate (VR).\n",
    "\n",
    "We use CPLFW dataset with distractors from MegaFace dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from ir_package.ir_class import IrBigData, calculate_inv_dict\n",
    "IrBigData._print_info = False\n",
    "\n",
    "if os.getcwd().endswith('quadrics') is not True:\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for representation article notation\n",
    "names_dict = {'OneClassSVM': 'OCSVM', 'norms': 'NORM', 'quadrics': 'Q-FULL', \n",
    "              'quadrics_alg': 'Q-SUB', 'basic_cosine': 'initial'}\n",
    "col_order = ['initial', 'Q-FULL', 'PCA', 'Q-SUB',  'OCSVM', 'NORM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the robustification techniques for which to train model and to calculate IR.\n",
    "**Note:** `'quadrics'` are not listed by default among model_to_train because their preparation takes very long time.\n",
    "\n",
    "Then run bash scripts to build the models corresponding to the listed techniques and save _CPLFW_ and _MegaFace_ features to features folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_train = ['OneClassSVM', 'PCA', 'norms']\n",
    "methods = ['PCA', 'norms', 'OneClassSVM', 'quadrics', 'quadrics_alg']\n",
    "\n",
    "! python3 create_models.py --methods {' '.join(methods_train)}\n",
    "! python3 calculate_features.py --methods {' '.join(methods)} --datasets cplfw megaface "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic similarity function is the standard cosine similarity. Because of this, for simplicity, we normalize embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cplfw_emb = normalize(np.load('image_embeddings/cplfw.npy'))\n",
    "megaface_emb = normalize(np.load('image_embeddings/megaface.npy'))\n",
    "\n",
    "with open('image_embeddings/labels/cplfw_labels.txt', encoding='utf-8') as txt_labels_file:\n",
    "    lines = txt_labels_file.readlines()\n",
    "cplfw_labels = np.array([i.rstrip('\\n') for i in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify parameters (see full list of parameters with explanations in the documentation for IrBigData class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_ir = {\n",
    "    \"similarity_type\": \"features\",\n",
    "    \"fpr_threshold\": 1e-5,\n",
    "    \"dist_type\": \"max_threshold\",\n",
    "    \"protocol\": \"data_distractors_no_false_pairs\",\n",
    "    \"N_distractors\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for each of the robustification techniques we run experiments with two similarity functions: the basic `cosine` and the robustified `features`.\n",
    "\n",
    "If we denote the basic `cosine` similarity by $s(x ,y) = \\langle x, y \\rangle$, then the robustified `features` similarity $s_h(x, y)$ is given by:\n",
    "\n",
    "$$s_h(x, y) = \\begin{cases}\n",
    "s(x ,y), &\\max({\\sf o}(x)), {\\sf o}(y))) < \\alpha, \\\\\n",
    "0, &\\max({\\sf o}(x), {\\sf o}(y)) \\geq \\alpha,\n",
    "\\end{cases}$$\n",
    "\n",
    "where $\\alpha$ is the threshold parameter and ${\\sf o}(x)$ is the list of features of $x$ given by the robustification technique.\n",
    "\n",
    "We tune $\\alpha$ by grid search in the vicinity of 0.99 quantile of features, that roughly corresponds to the portion of outliers in _CPFLW_ dataset.\n",
    "\n",
    "In each case we calculate both the identification and verification (identification with no outliers) rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(emb_names):\n",
    "    # split cplfw into 2 parts\n",
    "    inv_dict = calculate_inv_dict(emb_names)\n",
    "    keys = list(inv_dict.keys())\n",
    "    np.random.shuffle(keys)\n",
    "    indices_train, indices_test = [], []\n",
    "\n",
    "    for key in keys[:int(len(keys)/2)]:\n",
    "        indices_train.extend(inv_dict[key])\n",
    "\n",
    "    for key in keys[int(len(keys)/2):]:\n",
    "        indices_test.extend(inv_dict[key])\n",
    "\n",
    "    return indices_train, indices_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for method in methods+['basic_cosine']:\n",
    "    results_dict[method] = {}\n",
    "    results_dict[method]['ir'] = []\n",
    "    results_dict[method]['vr'] = []\n",
    "\n",
    "bar_exp = tqdm(range(4))\n",
    "for _ in bar_exp:\n",
    "    # choose random distractors\n",
    "    indices_random = np.random.choice(len(megaface_emb), \n",
    "                                      size=parameters_ir['N_distractors']*2, \n",
    "                                      replace=False)\n",
    "\n",
    "    megaface_emb = megaface_emb[indices_random]\n",
    "    indices_train, indices_test = get_train_test_split(cplfw_labels)\n",
    "\n",
    "    megaface_emb_train = megaface_emb[:parameters_ir['N_distractors']]\n",
    "    megaface_emb_test = megaface_emb[parameters_ir['N_distractors']:]\n",
    "    cplfw_emb_train = cplfw_emb[indices_train]\n",
    "    cplfw_emb_test = cplfw_emb[indices_test]\n",
    "\n",
    "    pbar = tqdm(methods, leave=False)\n",
    "    for method in pbar:\n",
    "        pbar.set_description(method)                \n",
    "        results_arr_train = []\n",
    "\n",
    "        cplfw_features = np.load('features/cplfw/{}_dist.npy'.format(method))\n",
    "        megaface_features = np.load('features/megaface/{}_dist.npy'.format(method))[indices_random]\n",
    "\n",
    "        cplfw_features_train = cplfw_features[indices_train]\n",
    "        cplfw_features_test = cplfw_features[indices_test]\n",
    "        megaface_features_train = megaface_features[:parameters_ir['N_distractors']]\n",
    "        megaface_features_test = megaface_features[parameters_ir['N_distractors']:]\n",
    "\n",
    "        IR = IrBigData(cplfw_emb_train, cplfw_features_train, \n",
    "                   cplfw_labels[indices_train], parameters_ir, distractors=megaface_emb_train, \n",
    "                   distractor_features=megaface_features_train)\n",
    "        IR.params['similarity_type'] = 'features'\n",
    "\n",
    "        quantiles_arr = [np.quantile(cplfw_features, i) for i in [0.985 + 0.001*i for i in range(10)]]\n",
    "        for alpha in tqdm(quantiles_arr, leave=False):\n",
    "            IR.params['alpha'] = alpha\n",
    "            IR.main()\n",
    "            results_arr_train.append(IR.CMT_)\n",
    "\n",
    "        parameters_ir['alpha'] = quantiles_arr[np.argmax(results_arr_train)]\n",
    "\n",
    "        IR = IrBigData(cplfw_emb_test, cplfw_features_test, \n",
    "               cplfw_labels[indices_test], parameters_ir, distractors=megaface_emb_test, \n",
    "               distractor_features=megaface_features_test)\n",
    "        IR.main()\n",
    "\n",
    "        results_dict[method]['ir'].append(IR.CMT_)\n",
    "        results_dict[method]['vr'].append(IR.VR_)\n",
    "\n",
    "    IR = IrBigData(cplfw_emb_test, None, cplfw_labels[indices_test], \n",
    "                   parameters_ir, distractors=megaface_emb_test, \n",
    "                   distractor_features=None)\n",
    "    IR.params['similarity_type'] = 'cosine'\n",
    "    IR.main()\n",
    "    results_dict['basic_cosine']['ir'].append(IR.CMT_)\n",
    "    results_dict['basic_cosine']['vr'].append(IR.VR_)\n",
    "\n",
    "    \n",
    "for method in methods+['basic_cosine']:\n",
    "    results_dict[method]['ir'] = np.mean(results_dict[method]['ir'])\n",
    "    results_dict[method]['vr'] = np.mean(results_dict[method]['vr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>Q-FULL</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Q-SUB</th>\n",
       "      <th>OCSVM</th>\n",
       "      <th>NORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ir</th>\n",
       "      <td>0.670617</td>\n",
       "      <td>0.743564</td>\n",
       "      <td>0.717837</td>\n",
       "      <td>0.693583</td>\n",
       "      <td>0.651183</td>\n",
       "      <td>0.742126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr</th>\n",
       "      <td>0.672771</td>\n",
       "      <td>0.746623</td>\n",
       "      <td>0.720175</td>\n",
       "      <td>0.695658</td>\n",
       "      <td>0.652996</td>\n",
       "      <td>0.745185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     initial    Q-FULL       PCA     Q-SUB     OCSVM      NORM\n",
       "ir  0.670617  0.743564  0.717837  0.693583  0.651183  0.742126\n",
       "vr  0.672771  0.746623  0.720175  0.695658  0.652996  0.745185"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame.from_dict(results_dict)\n",
    "df_result.rename(columns=names_dict)[col_order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "Note that the results in the following table do not need to coincide with the results from Table 2 of the paper. The reason is that in this notebook we took parameters_ir['N_distractors'] = 10000 while the results in the paper were obtained with parameters_ir['N_distractors'] = 500000 (the latter case is much longer to run).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
